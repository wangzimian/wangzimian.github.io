---
title: 'A High Performance Privacy Preserving Logistic Regression'
date: 2021-09-13
permalink: /posts/2021/09/blog-post-4/
tags:
  - MPC
  - Machine Learning
  - Logistic Regression
---

一个存在可信第三方的两方联合训练逻辑回归隐私保护模型

在机器学习隐私保护中，根据参与方的数目和模型角色的不同具体区分方案的差别。根据服务的扮演的角色不用，含可信第三方的两方安全计算以及计算地位相等的两方机器联合学习，两者的区别在是否需要可信第三方提供机器学习中乘法所需的三元组，若由可信中心提供三元组，联合计算方的通信量则会降低，至于降低多少根据方案设计而各不相同。另外在没有可信第三方辅助下，两方需要共同协商密钥和产生共用的乘法三元组，则需要产生通信。还有一种三方安全计算，三方的计算地位相对均等，其主要的计算难点是安全性假设、秘密共享方案和乘法，若是半诚实模型，用(3,3)秘密共享；若为最多一方为腐败的恶意模型，则均需采用(2,3)和(3,3)秘密共享。

此次文章高性能的[逻辑回归隐私保护](https://eprint.iacr.org/2020/171.pdf)方案。文章设计了两方安全计算协议，用梯度下降算法训练逻辑回归模型。新的激活函数不需要使用GC电路和密码学优化技术，实验模拟超过了七十亿次的安全乘法，可以在27秒内完成。方案假设数据由数据有单一方持有，并由拥有者分发给服务器，服务器不能处理相关的明文信息，但是这样会存在泄漏数据拥有者其他信息的风险。在这种挑战下利用安全多方计算技术保障数据的安全。一般而言，存在多个数据拥有者，他们都有训练数据不相交的部分，这样通用假设使得数据包括所有的分割数据。存在两个服务器处理训练数据并推导出模型，还假设存在一个可信第三方，分发相关随机性参数给服务器。在执行过程中假设可信中心不参与任何数据处理操作和中间参数设置。

**逻辑回归** 

逻辑回归是很常见的二分类机器学习模型。简单描述一下，样本数据$d = (x_d, t_d)$组成训练集$D$，其中$x_d = \langle x_{d,1}, \dots, x_{d, m} \rangle$是一个$m$维的向量。，每一条输入样本数据包含了$m$个值和$d$个特征值，$t_d \in \{0, 1\}$是类标签分类的标准(Groud Truth)。每一个$x_{d, i}$都是实数值。

